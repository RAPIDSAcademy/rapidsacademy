{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "## cuML\n",
    "[GitHub](https://github.com/rapidsai/cuml)\n",
    "\n",
    "cuML is a suite of libraries that implement machine learning algorithms and mathematical primitives functions that share compatible APIs with other RAPIDS projects.\n",
    "\n",
    "cuML enables data scientists, researchers, and software engineers to run traditional tabular ML tasks on GPUs without going into the details of CUDA programming. In most cases, cuML's Python API matches the API from scikit-learn.\n",
    "\n",
    "For large datasets, these GPU-based implementations can complete **10-50x** faster than their CPU equivalents.\n",
    "\n",
    "We'll show off a few examples to demonstrate the ease of using cuML. \n",
    "\n",
    "Parts of this were borrowed and lightly adapted from the cuML GitHub repository.\n",
    "\n",
    "#### DBScan\n",
    "Here is an an example of computing DBSCAN clusters entirely on GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "from cuml.cluster import DBSCAN\n",
    "\n",
    "# create and populate a GPU DataFrame\n",
    "gdf_float = cudf.DataFrame()\n",
    "gdf_float['0'] = [1.0, 2.0, 5.0]\n",
    "gdf_float['1'] = [4.0, 2.0, 1.0]\n",
    "gdf_float['2'] = [4.0, 2.0, 1.0]\n",
    "\n",
    "# setup and fit clusters\n",
    "dbscan_float = DBSCAN(eps=1.0, min_samples=1)\n",
    "dbscan_float.fit(gdf_float)\n",
    "\n",
    "dbscan_float.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression on Data in AWS S3\n",
    "To demonstrate how the RAPIDS stack integrates to easily create data pipelines we're going to run a simple workflow.\n",
    "\n",
    "We are going to predict the fare of a [NYC Yellow Taxi](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page) cab ride. We are going to do this by running a `LinearRegression()` on a `cudf.DataFrame`. \n",
    "\n",
    "This DataFrame will be generated from a SQL query on an *Apache Parquet* dataset that resides in *AWS S3*.\n",
    "\n",
    "For more information on BlazingSQL and cuDF see [The DataFrame Notebook](the_dataframe.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blazingsql import BlazingContext\n",
    "\n",
    "bc = BlazingContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.s3('blazingsql-colab', bucket_name='blazingsql-colab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.create_table('taxi', 's3://blazingsql-colab/yellow_taxi/1_0_0.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the desired features with `.sql()`, and then split up the data test using cuML's `train_test_split()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from cuml import LinearRegression\n",
    "from cuml.preprocessing.model_selection import train_test_split\n",
    "\n",
    "X = bc.sql('SELECT trip_distance, tolls_amount FROM taxi')\n",
    "y = bc.sql('SELECT fare_amount FROM taxi')['fare_amount']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run the `.fit()` and `.predict()` functions to perform the linear regression on the Taxi data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# call Linear Regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# train the model\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for test X values\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert test & predicted values `.to_pandas()` & find the model's `r2_score()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_true=y_test.to_pandas(), y_pred=y_pred.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Machine Learning\n",
    "\n",
    "cuML also features multi-GPU and multi-node-multi-GPU operation, using Dask, for a growing list of algorithms. \n",
    "\n",
    "The following Python snippet reads input from a Parquet file and performs a NearestNeighbors query across a cluster of Dask workers, using multiple GPUs on a single node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_cudf\n",
    "\n",
    "# read Parquet file in parallel across workers\n",
    "df = dask_cudf.read_parquet(\"../data/blobs.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "# identify client for cuml\n",
    "cluster = LocalCUDACluster()\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.dask.neighbors import NearestNeighbors\n",
    "\n",
    "# fit a NearestNeighbors model and query it\n",
    "nn = NearestNeighbors(client=client)\n",
    "\n",
    "nn.fit(df)\n",
    "\n",
    "distances, indices = nn.kneighbors(df, n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That is the Machine Learning Tour\n",
    "Those are but two simple examples of the algorithms supported by cuML.\n",
    "\n",
    "There are many more supported algorithms as you can see on the [cuML Github](https://github.com/rapidsai/cuml#supported-algorithms).\n",
    "\n",
    "That's all we have for now! Get coding your own workloads!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAPIDS Stable",
   "language": "python",
   "name": "rapids-stable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
